# OpenAI API Configuration

# Models available:
## gpt-3.5-turbo-1106: latest GPT-3.5 Turbo model with improved instruction following,
## JSON mode, reproducible outputs, parallel function calling, and more;
## returns a maximum of 4,096 output tokens; context window 16,385 tokens

## gpt-4-1106-preview: latest GPT-4 Turbo model with improved instruction following, JSON mode,
## reproducible outputs, parallel function calling, and more;
## returns a maximum of 4,096 output tokens; can handle window of 128,000 tokens

# gpt-4-32k: points to gpt-4-32k-0613; up to 32,768 tokens

# gpt-4: points to gpt-4-0613; up to 8.192 tokens

# gpt-4-vision-preview: understand images, in addition to all other GPT-4 Turbo capabilties;
## returns a maximum of 4,096 output tokens; can handle window of 128,000 tokens

OPENAI_API_KEY=sk-yourkeyhere
API_REQUEST_URL=https://api.openai.com/v1/chat/completions
MODEL_NAME=gpt-4-1106-preview

# Rate Limit Configuration
MAX_REQUESTS_PER_MINUTE=500
MAX_TOKENS_PER_MINUTE=60000
TOKEN_ENCODING_NAME=cl100k_base

# Request Handling Configuration
MAX_ATTEMPTS=5
LOGGING_LEVEL=20

# File Paths
INPUT_FILE_PATH=input.csv
REQUESTS_FILE_PATH=outputs/requests_to_chat_completion.jsonl
RESULTS_FILE_PATH=outputs/results_of_chat_completion.jsonl
OUTPUT_FILE_PATH=outputs/output.csv
DATA_PYTHON_PATH=data.py

# API Request Configuration
FREQUENCY_PENALTY=0
MAX_TOKENS=4096
PRESENCE_PENALTY=0
TEMPERATURE=0
TOP_P=0
N=1